# Web Scraping Challenge: Scraping the Entire "books.toscrape.com" Website

## Introduction

In our last session, we wrote a script to extract book data from a single page. Now, it's time to take your skills to the next level!

This exercise challenges you to apply and extend what you've learned to scrape the **entire** website, which contains 50 pages of book data.

**The goal of this exercise is to build your problem-solving and debugging skills.** Before you ask for help or search for a solution, try to figure out the challenges on your own. **Learning to debug is one of the most important skills you will develop as a programmer**.

## This Github Repo will guide you to the solution:

Before you use ChatGpt or anyother LLM try looking in the resources provided in this repository


## Your Challenge: Scrape All 50 Pages

Your task is to modify the initial script to scrape the **title** and **price** of every book from all 50 pages of the [Books to Scrape](http.books.toscrape.com/) website and save them into a single `books.csv` file.

### Getting Started

1.  Use the script from the last session.('you can find the script in `one_page_scraper.py` if you didnt attend the session)  
2.  **Do not modify this file.** Instead, create a copy and name it `scraper_all_pages.py`. You will work in this new file.
3.  Your goal is to modify `scraper_all_pages.py` so that it loops through all 50 pages and collects the data.





